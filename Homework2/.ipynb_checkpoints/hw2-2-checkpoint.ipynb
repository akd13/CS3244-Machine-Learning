{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework #2 - Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the README section for A0132788U's submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Notes** <br>\n",
    "The homework is formatted in accordance with the past homework and based on the tutorial. It uses the sklearn.svm module to make a support vector machine for a subset of the GISETTE dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Files Included in this Submission** <br>\n",
    "**hw-2-1.ipynb** : iPython notebook <br>\n",
    "**hw-2-2.ipynb** : iPython notebook <br>\n",
    "**essay2.pdf**: essay answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVM_train(X, Y, cost, kernel, gamma, N):\n",
    "    trainX = X\n",
    "    labelY = Y\n",
    "    trainX = np.matrix(trainX)\n",
    "    labelY = np.ravel(labelY)\n",
    "    if (N == -1):\n",
    "        svmModel = SVC(C=cost, kernel=kernel, gamma=gamma)\n",
    "    else:\n",
    "        svmModel = SVC(C=cost, kernel=kernel, gamma=gamma, degree=N, coef0=1.0);\n",
    "    svmModel.fit(trainX, labelY)  \n",
    "    totalSV = svmModel.support_.size\n",
    "    return svmModel,totalSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error(X,Y,clf):\n",
    "    sum = 0\n",
    "    N = len(X)\n",
    "    for i in range(N):\n",
    "        if (clf.predict(np.reshape(X[i],(1, -1)))[0] != Y[i][0]):\n",
    "            sum = sum + 1   \n",
    "    sum = sum/N   \n",
    "    return sum       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "#Training data\n",
    "insample_train_data = np.matrix(genfromtxt('hw2-1-train.txt'))\n",
    "Y_in = insample_train_data[:,0]\n",
    "insample_train_data = insample_train_data[:,1:3] #X_insample\n",
    "#print(insample_train_data)\n",
    "#print(Y_in)\n",
    "\n",
    "#Testing data\n",
    "outsample_test_data = np.matrix(genfromtxt('hw2-1-test.txt'))\n",
    "Y_out = outsample_test_data[:,0] \n",
    "outsample_test_data = outsample_test_data[:,1:3] #X_outsample\n",
    "#print(outsample_test_data)\n",
    "#print(Y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.a <br> No. of SV = 28, E_in = 0.003843689942344651 , E_out = 0.02122641509433962"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data,totalSV = SVM_train(insample_train_data, Y_in, 1.0, 'linear', 'auto', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E_in  = error(insample_train_data, Y_in, data)\n",
    "E_out = error(outsample_test_data, Y_out, data)\n",
    "#print(E_in)\n",
    "#print(E_out)\n",
    "kernel = 'linear'\n",
    "cost = 1.0\n",
    "trainAccuracy = 1 - E_in\n",
    "testAccuracy = 1 - E_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# report results in text file\n",
    "fo = open('problem-1.txt','w')\n",
    "fo.write(\"Kernel: \"+ str(kernel)+\"\\n\")\n",
    "fo.write(\"Cost: \"+ str(cost)+ \"\\n\")\n",
    "fo.write(\"Number of Support Vectors: \"+ str(totalSV)+\"\\n\")\n",
    "fo.write(\"Train Accuracy: \"+ str(trainAccuracy)+\"\\n\")\n",
    "fo.write(\"Test Accuracy: \" + str(testAccuracy)+\"\\n\")\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The required answers for the entire training data and the different subset sizes (50,100,200,800)  are given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset size is:  1561\n",
      "No. of SV: 28\n",
      "E_in is:  0.003843689942344651 and E_out is:  0.02122641509433962\n",
      "Train Accuracy is: 0.9961563100576554 and Test Accuracy is: 0.9787735849056604 \n",
      "\n",
      "Subset size is:  50\n",
      "No. of SV: 2\n",
      "E_in is:  0.0 and E_out is:  0.08\n",
      "Train Accuracy is: 1.0 and Test Accuracy is: 0.92 \n",
      "\n",
      "Subset size is:  100\n",
      "No. of SV: 4\n",
      "E_in is:  0.0 and E_out is:  0.02\n",
      "Train Accuracy is: 1.0 and Test Accuracy is: 0.98 \n",
      "\n",
      "Subset size is:  200\n",
      "No. of SV: 4\n",
      "E_in is:  0.0 and E_out is:  0.02\n",
      "Train Accuracy is: 1.0 and Test Accuracy is: 0.98 \n",
      "\n",
      "Subset size is:  800\n",
      "No. of SV: 10\n",
      "E_in is:  0.0025 and E_out is:  0.02122641509433962\n",
      "Train Accuracy is: 0.9975 and Test Accuracy is: 0.9787735849056604 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print subset results for sizes 50,100,200,800\n",
    "subsets = [len(insample_train_data),50,100,200,800]\n",
    "for N in subsets:\n",
    "    extract_inSample_trainXdata = insample_train_data[:N]\n",
    "    extract_inSample_labelYdata_in = Y_in[:N]\n",
    "    \n",
    "    extract_outSample_testXdata = outsample_test_data[:N]\n",
    "    extract_outSample_labelYdata_out = Y_out[:N]\n",
    "    \n",
    "    data_extract,totalSV = SVM_train(extract_inSample_trainXdata, extract_inSample_labelYdata_in, 1.0, 'linear', 'auto', 1)\n",
    "    \n",
    "    E_in  = error(extract_inSample_trainXdata, extract_inSample_labelYdata_in, data_extract)\n",
    "    E_out = error(extract_outSample_testXdata, extract_outSample_labelYdata_out, data_extract)\n",
    "    print(\"Subset size is: \", N)\n",
    "    print(\"No. of SV:\", totalSV)\n",
    "    print(\"E_in is: \",E_in,\"and E_out is: \",E_out)\n",
    "    print(\"Train Accuracy is:\",1-E_in, \"and Test Accuracy is:\",1-E_out,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b. Consider the polynomial kernel K(xn, xm) = (1 + xnTxm)Q, where Q is the degree of the polynomial. Comparing Q = 2 with Q = 5, which of the following statements is correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. When C = 0.0001, E_in is higher at Q = 5. FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_in for Degree 2 is: 0.008968609865470852 and E_in for Degree 5 is: 0.004484304932735426\n"
     ]
    }
   ],
   "source": [
    "ans_2,size_2 = SVM_train(insample_train_data, Y_in, 0.0001, 'poly', 1, 2)\n",
    "ans_5,size_5 = SVM_train(insample_train_data, Y_in, 0.0001, 'poly', 1, 5)\n",
    "errin_2 = error(insample_train_data, Y_in, ans_2)\n",
    "errin_5 = error(insample_train_data, Y_in, ans_5)\n",
    "print(\"E_in for Degree 2 is:\",errin_2,\"and E_in for Degree 5 is:\",errin_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. When C = 0.001, the number of support vectors is lower at Q = 5. TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of SV for Degree 2 is: 76 and No. of SV for Degree 5 is: 25\n"
     ]
    }
   ],
   "source": [
    "ans_2,size_2 = SVM_train(insample_train_data, Y_in, 0.001, 'poly', 1, 2)\n",
    "ans_5,size_5 = SVM_train(insample_train_data, Y_in, 0.001, 'poly', 1, 5)\n",
    "print(\"No. of SV for Degree 2 is:\",size_2,\"and No. of SV for Degree 5 is:\",size_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. When C = 0.01, E_in is higher at Q = 5. FALSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_in for Degree 2 is: 0.004484304932735426 and E_in for Degree 5 is: 0.003843689942344651\n"
     ]
    }
   ],
   "source": [
    "ans_2,size_2 = SVM_train(insample_train_data, Y_in, 0.01, 'poly', 1, 2)\n",
    "ans_5,size_5 = SVM_train(insample_train_data, Y_in, 0.01, 'poly', 1, 5)\n",
    "errin_2 = error(insample_train_data, Y_in, ans_2)\n",
    "errin_5 = error(insample_train_data, Y_in, ans_5)\n",
    "print(\"E_in for Degree 2 is:\",errin_2,\"and E_in for Degree 5 is:\",errin_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. When C = 1, E_out is lower at Q = 5. FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_out for Degree 2 is: 0.018867924528301886 and E_out for Degree 5 is: 0.02122641509433962\n"
     ]
    }
   ],
   "source": [
    "ans_2,size_2 = SVM_train(insample_train_data, Y_in, 1, 'poly', 1, 2)\n",
    "ans_5,size_5 = SVM_train(insample_train_data, Y_in, 1, 'poly', 1, 5)\n",
    "errout_2 = error(outsample_test_data, Y_out, ans_2)\n",
    "errout_5 = error(outsample_test_data, Y_out, ans_5)\n",
    "print(\"E_out for Degree 2 is:\",errout_2,\"and E_out for Degree 5 is:\",errout_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. False; Statement ii. is TRUE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c. Consider the radial basis function (RBF) kernel K(x_n, x_m) = e(-||xn - xm||2) in the soft-margin SVM approach. Which value of C âˆˆ {0.01, 1, 100, 10^4, 10^6} results in the lowest E_in? The lowest E_out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C is 0.01 \n",
      "E_in is: 0.003843689942344651 and E_out is: 0.02358490566037736 \n",
      "\n",
      "C is 1 \n",
      "E_in is: 0.004484304932735426 and E_out is: 0.02122641509433962 \n",
      "\n",
      "C is 100 \n",
      "E_in is: 0.0032030749519538757 and E_out is: 0.018867924528301886 \n",
      "\n",
      "C is 10000 \n",
      "E_in is: 0.0025624599615631004 and E_out is: 0.02358490566037736 \n",
      "\n",
      "C is 1000000 \n",
      "E_in is: 0.0006406149903907751 and E_out is: 0.02358490566037736 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "C_values = [0.01,1,100,10000,1000000]\n",
    "for c in C_values:\n",
    "    data_RBF,size = SVM_train(insample_train_data, Y_in, c, 'rbf', 1, 1)\n",
    "    err_in = error(insample_train_data,Y_in, data_RBF)\n",
    "    err_out = error(outsample_test_data,Y_out, data_RBF)\n",
    "    print(\"C is\",c, \"\\nE_in is:\",err_in,\"and E_out is:\",err_out,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The lowest value of E_in = 0.0006406149903907751 is when C =10^6. \n",
    "### The lowest value of E_out = 0.018867924528301886 is when C =100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statement of Individual Work\n",
    "\n",
    "Please initial (between the square brackets) one of the following statements.\n",
    "\n",
    "[ A. D] I, <*A0132788U*>, certify that I have followed the CS 3244 Machine Learning class guidelines for homework assignments.  In particular, I expressly vow that I have followed the Facebook rule in discussing with others in doing the assignment and did not take notes (digital or printed) from the discussions.  \n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "I have refered to the following list of people and websites in preparing my homework submission:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
