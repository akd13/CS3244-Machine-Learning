{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework #1 - The Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the README section for A0132788U's submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Notes about this assignment \n",
    "\n",
    "I imported the data using Pandas library. Since I'm not familiar with Python, I had a bit of trouble coding basic things and stuck to longer approaches/hard-coded some things that could have been done in an easier way, so I apologize for my code not being very readable. I have tried to document things as best as I could."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files included with this submission\n",
    "\n",
    "hw-1.ipynb : iPython notebook<br>\n",
    "essay1.pdf: essay answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import matplotlib.pyplot as pl\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "%matplotlib inline\n",
    "# Plotting with style! \n",
    "import seaborn as sb \n",
    "\n",
    "# Size the plot appropriately for online display\n",
    "pl.rcParams['figure.figsize'] = (12.0, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix the random number generator first, in case we need results that are replicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nr.seed(3244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load datasets code\n",
    "def load(filename):\n",
    "    # Use Pandas library to read data separated by at least one space\n",
    "    df = pd.read_table(filename, sep=\"\\s+\", header = None)\n",
    "    df.insert(0, '', 1) #Append bias term, extra column of 1s \n",
    "    df = df.as_matrix()\n",
    "    X = df[:,0:21] #Extract matrix X as data, dim is 1000 X 21\n",
    "    Y = df[:,21]   #Extract matrix Y as target, dim is 1000 X \n",
    "    Y = np.reshape(Y,(len(Y),1)) #reshape into 1000 X 1\n",
    "    return X,Y\n",
    "\n",
    "\n",
    "\n",
    "# LR code -For Batch Gradient Descent, Learning From Data Pg 95\n",
    "def lr(X,Y,weights, eta):\n",
    "    N = len(X) #Size of data\n",
    "    gradient = 0 #initialize to 0\n",
    "    for i in range(N):\n",
    "        xn = X[i] #ith row vector, tuple of X values\n",
    "        yn = Y[i] #ith column containing y value\n",
    "        gradient  = gradient + (-yn*xn)/(1+ np.exp(yn*np.dot(weights,xn)))        \n",
    "    gradient = gradient/N                              \n",
    "    vt = -gradient\n",
    "    weights = weights + eta*vt\n",
    "    return weights\n",
    "\n",
    "# LR code for Round robin Gradient Descent\n",
    "def lr_index(X,Y,weights, eta):\n",
    "    gradient = 0\n",
    "    gradient  = gradient + (-Y*X)/(1+ np.exp(Y*np.dot(weights,X)))                                   \n",
    "    vt = -gradient\n",
    "    weights = weights + eta*vt\n",
    "    return weights\n",
    "\n",
    "# Calculate Eout\n",
    "def E_out(X,Y, weights):\n",
    "    N = len(X) #Size of data\n",
    "    error_out = 0\n",
    "    for i in range(N):\n",
    "        xn = X[i]\n",
    "        yn = Y[i]\n",
    "        flag  = yn*np.dot(weights,xn) #If y*w(t)*x(t)<0, then incorrect classification\n",
    "        if(flag<0):\n",
    "             error_out = error_out + 1; #Add 1 for loss function\n",
    "\n",
    "    return error_out/N #take mean of errors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (a): η = 0.05 ,  T = 2333."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1161999  -0.62306389  0.83054698 -1.09349734  0.05572274 -1.11391388\n",
      " -0.01296555  1.11249534 -0.81588123  0.43092607  1.42346155  0.27688543\n",
      " -0.88095697 -0.59741621  0.85704225  1.15361007  1.30398967 -1.34807101\n",
      "  1.34243488 -0.6163682  -1.10064307]\n",
      "0.18433333333333332\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train = load(\"hw1-train.dat\")\n",
    "X_test,Y_test = load(\"hw1-test.dat\")\n",
    "weights = [0]*21 #initial array of zero vectors for weight\n",
    "for i in range(2333):\n",
    "    weights = lr(X_train,Y_train,weights, 0.05)\n",
    "\n",
    "print(weights)\n",
    "print(E_out(X_test,Y_test,weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (b): η = 0.005 ,  T = 2333."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00688555 -0.1144097   0.17133392 -0.21953818  0.03143198 -0.23767227\n",
      "  0.01827847  0.21209126 -0.16241842  0.08772493  0.31631168  0.05802732\n",
      " -0.15479096 -0.09603835  0.19544844  0.25837087  0.27707535 -0.29100915\n",
      "  0.2758916  -0.12857103 -0.23006944]\n",
      "0.26366666666666666\n"
     ]
    }
   ],
   "source": [
    "weights = [0]*21 #re-initialize array of zero vectors for weight\n",
    "for i in range(2333):\n",
    "    weights = lr(X_train,Y_train,weights, 0.005)\n",
    "\n",
    "print(weights)\n",
    "print(E_out(X_test,Y_test,weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (c): Use SGD and rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re-run of Part (a):\n",
      "[-0.136105   -0.71509139  0.87173522 -1.15471425 -0.04543836 -1.11559665\n",
      " -0.05679034  1.08370579 -0.92825167  0.4247163   1.40440587  0.17829297\n",
      " -0.79078275 -0.69854614  0.85446605  1.13068611  1.29620221 -1.47991206\n",
      "  1.41434789 -0.66007026 -1.0755395 ]\n",
      "0.22266666666666668\n",
      "\n",
      "\n",
      "re-run of Part (b):\n",
      "[-0.00587569 -0.13261359  0.1718377  -0.23245824 -0.00128913 -0.24747491\n",
      "  0.0045452   0.20677978 -0.17993033  0.0843913   0.30812906  0.03496958\n",
      " -0.14550272 -0.10943277  0.18726771  0.24725379  0.26877879 -0.3136832\n",
      "  0.27764022 -0.13889374 -0.22247117]\n",
      "0.19333333333333333\n"
     ]
    }
   ],
   "source": [
    "# re-run of part (a)\n",
    "weights = [0]*21\n",
    "for i in range(2333):\n",
    "    index = i % 1000 #divide by number of rows of X to get index in the form 1, 2, 3,...N, 1, 2..\n",
    "    weights = lr_index(X_train[index], Y_train[index], weights, eta=0.05)\n",
    "    \n",
    "print('re-run of Part (a):')    \n",
    "print(weights)\n",
    "print(E_out(X_test, Y_test, weights))\n",
    "\n",
    "print('\\n')\n",
    "# re-run of part (b)\n",
    "weights = [0]*21\n",
    "for i in range(2333):\n",
    "    index = i % 1000    \n",
    "    weights = lr_index(X_train[index], Y_train[index], weights, eta=0.005) \n",
    "    \n",
    "print('re-run of Part (b):')    \n",
    "print(weights)\n",
    "print(E_out(X_test, Y_test, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statement of Individual Work\n",
    "\n",
    "Please initial (between the square brackets) one of the following statements.\n",
    "\n",
    "[ A. D] I, <*A0132788U*>, certify that I have followed the CS 3244 Machine Learning class guidelines for homework assignments.  In particular, I expressly vow that I have followed the Facebook rule in discussing with others in doing the assignment and did not take notes (digital or printed) from the discussions.  \n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "I have refered to the following list of people and websites in preparing my homework submission:\n",
    "\n",
    "**Su Xuan, classmate** Discussion and verification of questions, he also suggested a Homework Template for LaTeX<br />\n",
    "**Learning from Data, Chapter 3** Logistic Regression<br />\n",
    "**StackOverFlow**: https://stackoverflow.com/questions/41025416/read-data-dat-file-with-pandas<br/>\n",
    "**Numpy documentation**:https://docs.scipy.org/doc/numpy-dev/user/quickstart.html<br/>\n",
    "**Essay question 2.a**:http://new.censusatschool.org.nz/wp-content/uploads/2012/11/Understanding-true-probability1.pdf<br/>\n",
    "**Essay question 2.c**: https://stats.stackexchange.com/questions/21581/how-to-assess-whether-a-coin-tossed-900-times-and-comes-up-heads-490-times-is-bi#comment39111_21581<br/>\n",
    "**Essay question 2.c**:http://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_confidence_intervals/bs704_confidence_intervals_print.html<br/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
